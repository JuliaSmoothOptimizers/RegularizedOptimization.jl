<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · RegularizedOptimization.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">RegularizedOptimization.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li class="is-active"><a class="tocitem" href>Reference</a><ul class="internal"><li><a class="tocitem" href="#Contents"><span>Contents</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/master/docs/src/reference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><h2 id="Contents"><a class="docs-heading-anchor" href="#Contents">Contents</a><a id="Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Contents" title="Permalink"></a></h2><ul><li><a href="#Reference">Reference</a></li><ul><li><a href="#Contents">Contents</a></li><li><a href="#Index">Index</a></li></ul></ul><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#RegularizedOptimization.ALSolver"><code>RegularizedOptimization.ALSolver</code></a></li><li><a href="#RegularizedOptimization.AL-Tuple{Val{:equ}, RegularizedProblems.AbstractRegularizedNLPModel}"><code>RegularizedOptimization.AL</code></a></li><li><a href="#RegularizedOptimization.FISTA-Tuple{NLPModels.AbstractNLPModel, Vararg{Any}}"><code>RegularizedOptimization.FISTA</code></a></li><li><a href="#RegularizedOptimization.LM-Union{Tuple{H}, Tuple{NLPModels.AbstractNLSModel, H, ROSolverOptions}} where H"><code>RegularizedOptimization.LM</code></a></li><li><a href="#RegularizedOptimization.LMTR-Union{Tuple{X}, Tuple{H}, Tuple{NLPModels.AbstractNLSModel, H, X, ROSolverOptions}} where {H, X}"><code>RegularizedOptimization.LMTR</code></a></li><li><a href="#RegularizedOptimization.PG-Tuple{NLPModels.AbstractNLPModel, Vararg{Any}}"><code>RegularizedOptimization.PG</code></a></li><li><a href="#RegularizedOptimization.R2-Union{Tuple{V}, Tuple{R}, Tuple{NLPModels.AbstractNLPModel{R, V}, Any, ROSolverOptions{R}}} where {R&lt;:Real, V}"><code>RegularizedOptimization.R2</code></a></li><li><a href="#RegularizedOptimization.R2DH-Union{Tuple{DQN}, Tuple{R}, Tuple{H}, Tuple{G}, Tuple{F}, Tuple{F, G, H, DQN, ROSolverOptions{R}, AbstractVector{R}}} where {F&lt;:Function, G&lt;:Function, H, R&lt;:Real, DQN&lt;:LinearOperators.AbstractDiagonalQuasiNewtonOperator}"><code>RegularizedOptimization.R2DH</code></a></li><li><a href="#RegularizedOptimization.R2DH-Union{Tuple{S}, Tuple{R}, Tuple{NLPModelsModifiers.AbstractDiagonalQNModel{R, S}, Any, ROSolverOptions{R}}} where {R&lt;:Real, S}"><code>RegularizedOptimization.R2DH</code></a></li><li><a href="#RegularizedOptimization.R2N-Union{Tuple{R}, Tuple{H}, Tuple{NLPModels.AbstractNLPModel, H, ROSolverOptions{R}}} where {H, R}"><code>RegularizedOptimization.R2N</code></a></li><li><a href="#RegularizedOptimization.RegularizedExecutionStats-Union{Tuple{RegularizedProblems.AbstractRegularizedNLPModel{T, V}}, Tuple{V}, Tuple{T}} where {T, V}"><code>RegularizedOptimization.RegularizedExecutionStats</code></a></li><li><a href="#RegularizedOptimization.TR-Union{Tuple{R}, Tuple{X}, Tuple{H}, Tuple{NLPModels.AbstractNLPModel, H, X, ROSolverOptions{R}}} where {H, X, R}"><code>RegularizedOptimization.TR</code></a></li><li><a href="#RegularizedOptimization.TRDH-Union{Tuple{S}, Tuple{R}, Tuple{NLPModelsModifiers.AbstractDiagonalQNModel{R, S}, Any, Any, ROSolverOptions{R}}} where {R&lt;:Real, S}"><code>RegularizedOptimization.TRDH</code></a></li><li><a href="#RegularizedOptimization.project_y!-Tuple{Percival.AugLagModel}"><code>RegularizedOptimization.project_y!</code></a></li><li><a href="#RegularizedOptimization.prox_split_1w-NTuple{4, Any}"><code>RegularizedOptimization.prox_split_1w</code></a></li><li><a href="#RegularizedOptimization.prox_split_2w-NTuple{4, Any}"><code>RegularizedOptimization.prox_split_2w</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.ALSolver" href="#RegularizedOptimization.ALSolver"><code>RegularizedOptimization.ALSolver</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">AL(reg_nlp; kwargs...)</code></pre><p>An augmented Lagrangian method for constrained regularized optimization, namely problems in the form</p><pre><code class="language-none">minimize    f(x) + h(x)
subject to  lvar ≤ x ≤ uvar,
            lcon ≤ c(x) ≤ ucon</code></pre><p>where f: ℝⁿ → ℝ, c: ℝⁿ → ℝᵐ and their derivatives are Lipschitz continuous and h: ℝⁿ → ℝ is lower semi-continuous, proper and prox-bounded.</p><p>At each iteration, an iterate x is computed as an approximate solution of the subproblem</p><pre><code class="language-none">minimize    L(x;y,μ) + h(x)
subject to  lvar ≤ x ≤ uvar</code></pre><p>where y is an estimate of the Lagrange multiplier vector for the constraints lcon ≤ c(x) ≤ ucon,  μ is the penalty parameter and L(⋅;y,μ) is the augmented Lagrangian function defined by</p><pre><code class="language-none">L(x;y,μ) := f(x) - yᵀc(x) + ½ μ ‖c(x)‖².</code></pre><p>For advanced usage, first define a solver &quot;ALSolver&quot; to preallocate the memory used in the algorithm, and then call <code>solve!</code>:</p><pre><code class="language-none">solver = ALSolver(reg_nlp)
solve!(solver, reg_nlp)

stats = GenericExecutionStats(reg_nlp.model)
solver = ALSolver(reg_nlp)
solve!(solver, reg_nlp, stats)</code></pre><p><strong>Arguments</strong></p><ul><li><code>reg_nlp::AbstractRegularizedNLPModel</code>: a regularized optimization problem, see <code>RegularizedProblems.jl</code>,  consisting of <code>model</code> representing a smooth optimization problem, see <code>NLPModels.jl</code>, and a regularizer <code>h</code> such as those defined in <code>ProximalOperators.jl</code>.</li></ul><p>The objective and gradient of <code>model</code> will be accessed. The Hessian of <code>model</code> may be accessed or not, depending on the subsolver adopted. If adopted, the Hessian is accessed as an abstract operator and need not be the exact Hessian.</p><p><strong>Keyword arguments</strong></p><ul><li><code>x::AbstractVector</code>: a primal initial guess (default: <code>reg_nlp.model.meta.x0</code>)</li><li><code>y::AbstractVector</code>: a dual initial guess (default: <code>reg_nlp.model.meta.y0</code>)</li><li><code>atol::T = √eps(T)</code>: absolute optimality tolerance;</li><li><code>ctol::T = atol</code>: absolute feasibility tolerance;</li><li><code>verbose::Int = 0</code>: if &gt; 0, display iteration details every <code>verbose</code> iteration;</li><li><code>max_iter::Int = 10000</code>: maximum number of iterations;</li><li><code>max_time::Float64 = 30.0</code>: maximum time limit in seconds;</li><li><code>max_eval::Int = -1</code>: maximum number of evaluation of the objective function (negative number means unlimited);</li><li><code>subsolver::AbstractOptimizationSolver = has_bounds(nlp) ? TR : R2</code>: the procedure used to compute a step (e.g. <code>PG</code>, <code>R2</code>, <code>TR</code> or <code>TRDH</code>);</li><li><code>subsolver_logger::AbstractLogger</code>: a logger to pass to the subproblem solver;</li><li><code>init_penalty::T = T(10)</code>: initial penalty parameter;</li><li><code>factor_penalty_up::T = T(2)</code>: multiplicative factor to increase the penalty parameter;</li><li><code>factor_primal_linear_improvement::T = T(3/4)</code>: fraction to declare sufficient improvement of feasibility;</li><li><code>init_subtol::T = T(0.1)</code>: initial subproblem tolerance;</li><li><code>factor_decrease_subtol::T = T(1/4)</code>: multiplicative factor to decrease the subproblem tolerance;</li><li><code>dual_safeguard = (nlp::AugLagModel) -&gt; nothing</code>: in-place function to modify, as needed, the dual estimate.</li></ul><p><strong>Output</strong></p><ul><li><code>stats::GenericExecutionStats</code>: solution and other info, see <code>SolverCore.jl</code>.</li></ul><p><strong>Callback</strong></p><p>The callback is called at each iteration. The expected signature of the callback is <code>callback(nlp, solver, stats)</code>, and its output is ignored. Changing any of the input arguments will affect the subsequent iterations. In particular, setting <code>stats.status = :user</code> will stop the algorithm. All relevant information should be available in <code>reg_nlp</code> and <code>solver</code>. Notably, you can access, and modify, the following:</p><ul><li><code>solver.x</code>: current iterate;</li><li><code>solver.y</code>: current dual estimate;</li><li><code>stats</code>: structure holding the output of the algorithm (<code>GenericExecutionStats</code>), which contains, among other things:<ul><li><code>stats.iter</code>: current iteration counter;</li><li><code>stats.objective</code>: current objective function value;</li><li><code>stats.status</code>: current status of the algorithm. Should be <code>:unknown</code> unless the algorithm has attained a stopping criterion. Changing this to anything will stop the algorithm, but you should use <code>:user</code> to properly indicate the intention;</li><li><code>stats.elapsed_time</code>: elapsed time in seconds;</li><li><code>stats.solver_specific[:smooth_obj]</code>: current value of the smooth part of the objective function;</li><li><code>stats.solver_specific[:nonsmooth_obj]</code>: current value of the nonsmooth part of the objective function.</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/AL_alg.jl#L60-L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.AL-Tuple{Val{:equ}, RegularizedProblems.AbstractRegularizedNLPModel}" href="#RegularizedOptimization.AL-Tuple{Val{:equ}, RegularizedProblems.AbstractRegularizedNLPModel}"><code>RegularizedOptimization.AL</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">AL(reg_nlp; kwargs...)</code></pre><p>An augmented Lagrangian method for constrained regularized optimization, namely problems in the form</p><pre><code class="language-none">minimize    f(x) + h(x)
subject to  lvar ≤ x ≤ uvar,
            lcon ≤ c(x) ≤ ucon</code></pre><p>where f: ℝⁿ → ℝ, c: ℝⁿ → ℝᵐ and their derivatives are Lipschitz continuous and h: ℝⁿ → ℝ is lower semi-continuous, proper and prox-bounded.</p><p>At each iteration, an iterate x is computed as an approximate solution of the subproblem</p><pre><code class="language-none">minimize    L(x;y,μ) + h(x)
subject to  lvar ≤ x ≤ uvar</code></pre><p>where y is an estimate of the Lagrange multiplier vector for the constraints lcon ≤ c(x) ≤ ucon,  μ is the penalty parameter and L(⋅;y,μ) is the augmented Lagrangian function defined by</p><pre><code class="language-none">L(x;y,μ) := f(x) - yᵀc(x) + ½ μ ‖c(x)‖².</code></pre><p>For advanced usage, first define a solver &quot;ALSolver&quot; to preallocate the memory used in the algorithm, and then call <code>solve!</code>:</p><pre><code class="language-none">solver = ALSolver(reg_nlp)
solve!(solver, reg_nlp)

stats = GenericExecutionStats(reg_nlp.model)
solver = ALSolver(reg_nlp)
solve!(solver, reg_nlp, stats)</code></pre><p><strong>Arguments</strong></p><ul><li><code>reg_nlp::AbstractRegularizedNLPModel</code>: a regularized optimization problem, see <code>RegularizedProblems.jl</code>,  consisting of <code>model</code> representing a smooth optimization problem, see <code>NLPModels.jl</code>, and a regularizer <code>h</code> such as those defined in <code>ProximalOperators.jl</code>.</li></ul><p>The objective and gradient of <code>model</code> will be accessed. The Hessian of <code>model</code> may be accessed or not, depending on the subsolver adopted. If adopted, the Hessian is accessed as an abstract operator and need not be the exact Hessian.</p><p><strong>Keyword arguments</strong></p><ul><li><code>x::AbstractVector</code>: a primal initial guess (default: <code>reg_nlp.model.meta.x0</code>)</li><li><code>y::AbstractVector</code>: a dual initial guess (default: <code>reg_nlp.model.meta.y0</code>)</li><li><code>atol::T = √eps(T)</code>: absolute optimality tolerance;</li><li><code>ctol::T = atol</code>: absolute feasibility tolerance;</li><li><code>verbose::Int = 0</code>: if &gt; 0, display iteration details every <code>verbose</code> iteration;</li><li><code>max_iter::Int = 10000</code>: maximum number of iterations;</li><li><code>max_time::Float64 = 30.0</code>: maximum time limit in seconds;</li><li><code>max_eval::Int = -1</code>: maximum number of evaluation of the objective function (negative number means unlimited);</li><li><code>subsolver::AbstractOptimizationSolver = has_bounds(nlp) ? TR : R2</code>: the procedure used to compute a step (e.g. <code>PG</code>, <code>R2</code>, <code>TR</code> or <code>TRDH</code>);</li><li><code>subsolver_logger::AbstractLogger</code>: a logger to pass to the subproblem solver;</li><li><code>init_penalty::T = T(10)</code>: initial penalty parameter;</li><li><code>factor_penalty_up::T = T(2)</code>: multiplicative factor to increase the penalty parameter;</li><li><code>factor_primal_linear_improvement::T = T(3/4)</code>: fraction to declare sufficient improvement of feasibility;</li><li><code>init_subtol::T = T(0.1)</code>: initial subproblem tolerance;</li><li><code>factor_decrease_subtol::T = T(1/4)</code>: multiplicative factor to decrease the subproblem tolerance;</li><li><code>dual_safeguard = (nlp::AugLagModel) -&gt; nothing</code>: in-place function to modify, as needed, the dual estimate.</li></ul><p><strong>Output</strong></p><ul><li><code>stats::GenericExecutionStats</code>: solution and other info, see <code>SolverCore.jl</code>.</li></ul><p><strong>Callback</strong></p><p>The callback is called at each iteration. The expected signature of the callback is <code>callback(nlp, solver, stats)</code>, and its output is ignored. Changing any of the input arguments will affect the subsequent iterations. In particular, setting <code>stats.status = :user</code> will stop the algorithm. All relevant information should be available in <code>reg_nlp</code> and <code>solver</code>. Notably, you can access, and modify, the following:</p><ul><li><code>solver.x</code>: current iterate;</li><li><code>solver.y</code>: current dual estimate;</li><li><code>stats</code>: structure holding the output of the algorithm (<code>GenericExecutionStats</code>), which contains, among other things:<ul><li><code>stats.iter</code>: current iteration counter;</li><li><code>stats.objective</code>: current objective function value;</li><li><code>stats.status</code>: current status of the algorithm. Should be <code>:unknown</code> unless the algorithm has attained a stopping criterion. Changing this to anything will stop the algorithm, but you should use <code>:user</code> to properly indicate the intention;</li><li><code>stats.elapsed_time</code>: elapsed time in seconds;</li><li><code>stats.solver_specific[:smooth_obj]</code>: current value of the smooth part of the objective function;</li><li><code>stats.solver_specific[:nonsmooth_obj]</code>: current value of the nonsmooth part of the objective function.</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/AL_alg.jl#L60-L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.FISTA-Tuple{NLPModels.AbstractNLPModel, Vararg{Any}}" href="#RegularizedOptimization.FISTA-Tuple{NLPModels.AbstractNLPModel, Vararg{Any}}"><code>RegularizedOptimization.FISTA</code></a> — <span class="docstring-category">Method</span></header><section><div><p>FISTA for   min_x ϕ(x) = f(x) + g(x), with f(x) cvx and β-smooth, g(x) closed cvx</p><p>Input:     f: function handle that returns f(x) and ∇f(x)     h: function handle that returns g(x)     s: initial point     proxG: function handle that calculates prox_{νg}     options: see descentopts.jl   Output:     s⁺: s update     s : s^(k-1)     his : function history     feval : number of function evals (total objective)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/Fista_alg.jl#L3-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.LM-Union{Tuple{H}, Tuple{NLPModels.AbstractNLSModel, H, ROSolverOptions}} where H" href="#RegularizedOptimization.LM-Union{Tuple{H}, Tuple{NLPModels.AbstractNLSModel, H, ROSolverOptions}} where H"><code>RegularizedOptimization.LM</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">LM(nls, h, options; kwargs...)</code></pre><p>A Levenberg-Marquardt method for the problem</p><pre><code class="language-none">min ½ ‖F(x)‖² + h(x)</code></pre><p>where F: ℝⁿ → ℝᵐ and its Jacobian J are Lipschitz continuous and h: ℝⁿ → ℝ is lower semi-continuous, proper and prox-bounded.</p><p>At each iteration, a step s is computed as an approximate solution of</p><pre><code class="language-none">min  ½ ‖J(x) s + F(x)‖² + ½ σ ‖s‖² + ψ(s; x)</code></pre><p>where F(x) and J(x) are the residual and its Jacobian at x, respectively, ψ(s; x) = h(x + s), and σ &gt; 0 is a regularization parameter.</p><p><strong>Arguments</strong></p><ul><li><code>nls::AbstractNLSModel</code>: a smooth nonlinear least-squares problem</li><li><code>h</code>: a regularizer such as those defined in ProximalOperators</li><li><code>options::ROSolverOptions</code>: a structure containing algorithmic parameters</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>x0::AbstractVector</code>: an initial guess (default: <code>nls.meta.x0</code>)</li><li><code>subsolver_logger::AbstractLogger</code>: a logger to pass to the subproblem solver</li><li><code>subsolver</code>: the procedure used to compute a step (<code>PG</code>, <code>R2</code> or <code>TRDH</code>)</li><li><code>subsolver_options::ROSolverOptions</code>: default options to pass to the subsolver.</li><li><code>selected::AbstractVector{&lt;:Integer}</code>: (default <code>1:nls.meta.nvar</code>).</li></ul><p><strong>Return values</strong></p><ul><li><code>xk</code>: the final iterate</li><li><code>Fobj_hist</code>: an array with the history of values of the smooth objective</li><li><code>Hobj_hist</code>: an array with the history of values of the nonsmooth objective</li><li><code>Complex_hist</code>: an array with the history of number of inner iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/LM_alg.jl#L3-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.LMTR-Union{Tuple{X}, Tuple{H}, Tuple{NLPModels.AbstractNLSModel, H, X, ROSolverOptions}} where {H, X}" href="#RegularizedOptimization.LMTR-Union{Tuple{X}, Tuple{H}, Tuple{NLPModels.AbstractNLSModel, H, X, ROSolverOptions}} where {H, X}"><code>RegularizedOptimization.LMTR</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">LMTR(nls, h, χ, options; kwargs...)</code></pre><p>A trust-region Levenberg-Marquardt method for the problem</p><pre><code class="language-none">min ½ ‖F(x)‖² + h(x)</code></pre><p>where F: ℝⁿ → ℝᵐ and its Jacobian J are Lipschitz continuous and h: ℝⁿ → ℝ is lower semi-continuous and proper.</p><p>At each iteration, a step s is computed as an approximate solution of</p><pre><code class="language-none">min  ½ ‖J(x) s + F(x)‖₂² + ψ(s; x)  subject to  ‖s‖ ≤ Δ</code></pre><p>where F(x) and J(x) are the residual and its Jacobian at x, respectively, ψ(s; x) = h(x + s), ‖⋅‖ is a user-defined norm and Δ &gt; 0 is a trust-region radius.</p><p><strong>Arguments</strong></p><ul><li><code>nls::AbstractNLSModel</code>: a smooth nonlinear least-squares problem</li><li><code>h</code>: a regularizer such as those defined in ProximalOperators</li><li><code>χ</code>: a norm used to define the trust region in the form of a regularizer</li><li><code>options::ROSolverOptions</code>: a structure containing algorithmic parameters</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>x0::AbstractVector</code>: an initial guess (default: <code>nls.meta.x0</code>)</li><li><code>subsolver_logger::AbstractLogger</code>: a logger to pass to the subproblem solver</li><li><code>subsolver</code>: the procedure used to compute a step (<code>PG</code>, <code>R2</code> or <code>TRDH</code>)</li><li><code>subsolver_options::ROSolverOptions</code>: default options to pass to the subsolver.</li><li><code>selected::AbstractVector{&lt;:Integer}</code>: (default <code>1:nls.meta.nvar</code>).</li></ul><p><strong>Return values</strong></p><ul><li><code>xk</code>: the final iterate</li><li><code>Fobj_hist</code>: an array with the history of values of the smooth objective</li><li><code>Hobj_hist</code>: an array with the history of values of the nonsmooth objective</li><li><code>Complex_hist</code>: an array with the history of number of inner iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/LMTR_alg.jl#L3-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.PG-Tuple{NLPModels.AbstractNLPModel, Vararg{Any}}" href="#RegularizedOptimization.PG-Tuple{NLPModels.AbstractNLPModel, Vararg{Any}}"><code>RegularizedOptimization.PG</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Proximal Gradient Descent  for</p><p>min_x ϕ(x) = f(x) + g(x), with f(x) β-smooth, g(x) closed, lsc</p><p>Input:   f: function handle that returns f(x) and ∇f(x)   h: function handle that returns g(x)   s: initial point   proxG: function handle that calculates prox_{νg}   options: see descentopts.jl Output:   s⁺: s update   s : s^(k-1)   his : function history   feval : number of function evals (total objective )</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/PG_alg.jl#L3-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.R2-Union{Tuple{V}, Tuple{R}, Tuple{NLPModels.AbstractNLPModel{R, V}, Any, ROSolverOptions{R}}} where {R&lt;:Real, V}" href="#RegularizedOptimization.R2-Union{Tuple{V}, Tuple{R}, Tuple{NLPModels.AbstractNLPModel{R, V}, Any, ROSolverOptions{R}}} where {R&lt;:Real, V}"><code>RegularizedOptimization.R2</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">R2(reg_nlp; kwargs…)</code></pre><p>A first-order quadratic regularization method for the problem</p><pre><code class="language-none">min f(x) + h(x)</code></pre><p>where f: ℝⁿ → ℝ has a Lipschitz-continuous gradient, and h: ℝⁿ → ℝ is lower semi-continuous, proper and prox-bounded.</p><p>About each iterate xₖ, a step sₖ is computed as a solution of</p><pre><code class="language-none">min  φ(s; xₖ) + ½ σₖ ‖s‖² + ψ(s; xₖ)</code></pre><p>where φ(s ; xₖ) = f(xₖ) + ∇f(xₖ)ᵀs is the Taylor linear approximation of f about xₖ, ψ(s; xₖ) is either h(xₖ + s) or an approximation of h(xₖ + s), ‖⋅‖ is a user-defined norm and σₖ &gt; 0 is the regularization parameter.</p><p>For advanced usage, first define a solver &quot;R2Solver&quot; to preallocate the memory used in the algorithm, and then call <code>solve!</code>:</p><pre><code class="language-none">solver = R2Solver(reg_nlp)
solve!(solver, reg_nlp)

stats = RegularizedExecutionStats(reg_nlp)
solver = R2Solver(reg_nlp)
solve!(solver, reg_nlp, stats)</code></pre><p><strong>Arguments</strong></p><ul><li><code>reg_nlp::AbstractRegularizedNLPModel{T, V}</code>: the problem to solve, see <code>RegularizedProblems.jl</code>, <code>NLPModels.jl</code>.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>x::V = nlp.meta.x0</code>: the initial guess;</li><li><code>atol::T = √eps(T)</code>: absolute tolerance;</li><li><code>rtol::T = √eps(T)</code>: relative tolerance;</li><li><code>neg_tol::T = eps(T)^(1 / 4)</code>: negative tolerance</li><li><code>max_eval::Int = -1</code>: maximum number of evaluation of the objective function (negative number means unlimited);</li><li><code>max_time::Float64 = 30.0</code>: maximum time limit in seconds;</li><li><code>max_iter::Int = 10000</code>: maximum number of iterations;</li><li><code>verbose::Int = 0</code>: if &gt; 0, display iteration details every <code>verbose</code> iteration;</li><li><code>σmin::T = eps(T)</code>: minimum value of the regularization parameter;</li><li><code>η1::T = √√eps(T)</code>: very successful iteration threshold;</li><li><code>η2::T = T(0.9)</code>: successful iteration threshold;</li><li><code>ν::T = eps(T)^(1 / 5)</code>: multiplicative inverse of the regularization parameter: ν = 1/σ;</li><li><code>γ::T = T(3)</code>: regularization parameter multiplier, σ := σ/γ when the iteration is very successful and σ := σγ when the iteration is unsuccessful.</li></ul><p>The algorithm stops either when <code>√(ξₖ/νₖ) &lt; atol + rtol*√(ξ₀/ν₀)</code> or <code>ξₖ &lt; 0</code> and <code>√(-ξₖ/νₖ) &lt; neg_tol</code> where ξₖ := f(xₖ) + h(xₖ) - φ(sₖ; xₖ) - ψ(sₖ; xₖ), and √(ξₖ/νₖ) is a stationarity measure.</p><p><strong>Output</strong></p><p>The value returned is a <code>GenericExecutionStats</code>, see <code>SolverCore.jl</code>.</p><p><strong>Callback</strong></p><p>The callback is called at each iteration. The expected signature of the callback is <code>callback(nlp, solver, stats)</code>, and its output is ignored. Changing any of the input arguments will affect the subsequent iterations. In particular, setting <code>stats.status = :user</code> will stop the algorithm. All relevant information should be available in <code>nlp</code> and <code>solver</code>. Notably, you can access, and modify, the following:</p><ul><li><code>solver.xk</code>: current iterate;</li><li><code>solver.∇fk</code>: current gradient;</li><li><code>stats</code>: structure holding the output of the algorithm (<code>GenericExecutionStats</code>), which contains, among other things:<ul><li><code>stats.iter</code>: current iteration counter;</li><li><code>stats.objective</code>: current objective function value;</li><li><code>stats.solver_specific[:smooth_obj]</code>: current value of the smooth part of the objective function</li><li><code>stats.solver_specific[:nonsmooth_obj]</code>: current value of the nonsmooth part of the objective function</li><li><code>stats.status</code>: current status of the algorithm. Should be <code>:unknown</code> unless the algorithm has attained a stopping criterion. Changing this to anything will stop the algorithm, but you should use <code>:user</code> to properly indicate the intention.</li><li><code>stats.elapsed_time</code>: elapsed time in seconds.</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/R2_alg.jl#L113-L178">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.R2DH-Union{Tuple{DQN}, Tuple{R}, Tuple{H}, Tuple{G}, Tuple{F}, Tuple{F, G, H, DQN, ROSolverOptions{R}, AbstractVector{R}}} where {F&lt;:Function, G&lt;:Function, H, R&lt;:Real, DQN&lt;:LinearOperators.AbstractDiagonalQuasiNewtonOperator}" href="#RegularizedOptimization.R2DH-Union{Tuple{DQN}, Tuple{R}, Tuple{H}, Tuple{G}, Tuple{F}, Tuple{F, G, H, DQN, ROSolverOptions{R}, AbstractVector{R}}} where {F&lt;:Function, G&lt;:Function, H, R&lt;:Real, DQN&lt;:LinearOperators.AbstractDiagonalQuasiNewtonOperator}"><code>RegularizedOptimization.R2DH</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">R2DH(f, ∇f!, h, options, x0)</code></pre><p>A second calling form for <code>R2DH</code> where the objective and gradient are passed as arguments.</p><p><strong>Arguments</strong></p><ul><li><code>f::Function</code>: the objective function</li><li><code>∇f!::Function</code>: the gradient function</li><li><code>h</code>: a regularizer such as those defined in ProximalOperators</li><li><code>D</code>: Diagonal quasi-Newton operator.</li><li><code>options::ROSolverOptions</code>: a structure containing algorithmic parameters</li><li><code>x0::AbstractVector</code>: an initial guess</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>Mmonotone::Int</code>: number of previous values of the objective to consider for the non-monotone variant (default: 6).</li><li><code>selected::AbstractVector{&lt;:Integer}</code>: subset of variables to which <code>h</code> is applied (default <code>1:length(x0)</code>).</li></ul><p><strong>Return values</strong></p><ul><li><code>xk</code>: the final iterate</li><li><code>k</code>: the number of iterations</li><li><code>outdict</code>: a dictionary containing the following fields:<ul><li><code>Fhist</code>: an array with the history of values of the smooth objective</li><li><code>Hhist</code>: an array with the history of values of the nonsmooth objective</li><li><code>Time_hist</code>: an array with the history of elapsed times</li><li><code>Chist</code>: an array with the history of number of inner iterations</li><li><code>NonSmooth</code>: the nonsmooth term</li><li><code>status</code>: the status of the solver either <code>:first_order</code>, <code>:max_iter</code>, <code>:max_time</code> or <code>:exception</code></li><li><code>fk</code>: the value of the smooth objective at the final iterate</li><li><code>hk</code>: the value of the nonsmooth objective at the final iterate</li><li><code>sqrt_ξ_νInv</code>: the square root of the ratio of the nonsmooth term to the regularization parameter</li><li><code>elapsed_time</code>: the elapsed time</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/R2DH.jl#L73-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.R2DH-Union{Tuple{S}, Tuple{R}, Tuple{NLPModelsModifiers.AbstractDiagonalQNModel{R, S}, Any, ROSolverOptions{R}}} where {R&lt;:Real, S}" href="#RegularizedOptimization.R2DH-Union{Tuple{S}, Tuple{R}, Tuple{NLPModelsModifiers.AbstractDiagonalQNModel{R, S}, Any, ROSolverOptions{R}}} where {R&lt;:Real, S}"><code>RegularizedOptimization.R2DH</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">R2DH(nlp, h, options)</code></pre><p>A second-order quadratic regularization method for the problem</p><pre><code class="language-none">min f(x) + h(x)</code></pre><p>where f: ℝⁿ → ℝ is C¹ and h: ℝⁿ → ℝ is lower semi-continuous, proper, and prox-bounded.</p><p>About each iterate xₖ, a step sₖ is computed as a solution of</p><pre><code class="language-none">min  φ(s; xₖ) + ψ(s; xₖ)</code></pre><p>where φ(s ; xₖ) = f(xₖ) + ∇f(xₖ)ᵀs + ½ sᵀ(Dₖ + σₖI)s is a quadratic approximation of f about xₖ, ψ(s; xₖ) = h(xₖ + s), Dₖ is a diagonal Hessian approximation and σₖ &gt; 0 is the regularization parameter.</p><p><strong>Arguments</strong></p><ul><li><code>nlp::AbstractDiagonalQNModel</code>: a smooth optimization problem</li><li><code>h</code>: a regularizer such as those defined in ProximalOperators</li><li><code>options::ROSolverOptions</code>: a structure containing algorithmic parameters</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>x0::AbstractVector</code>: an initial guess (in the first calling form: default = <code>nlp.meta.x0</code>)</li><li><code>selected::AbstractVector{&lt;:Integer}</code>: subset of variables to which <code>h</code> is applied (default <code>1:length(x0)</code>).</li><li><code>D</code>: Diagonal quasi-Newton operator.</li><li><code>Mmonotone::Int</code>: number of previous values of the objective to consider for the non-monotone variant (default: 6).</li></ul><p>The objective and gradient of <code>nlp</code> will be accessed.</p><p><strong>Return values</strong></p><p>The value returned is a <code>GenericExecutionStats</code>, see <code>SolverCore.jl</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/R2DH.jl#L3-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.R2N-Union{Tuple{R}, Tuple{H}, Tuple{NLPModels.AbstractNLPModel, H, ROSolverOptions{R}}} where {H, R}" href="#RegularizedOptimization.R2N-Union{Tuple{R}, Tuple{H}, Tuple{NLPModels.AbstractNLPModel, H, ROSolverOptions{R}}} where {H, R}"><code>RegularizedOptimization.R2N</code></a> — <span class="docstring-category">Method</span></header><section><div><p>R2N(nlp, h, χ, options; kwargs...)</p><p>A regularized quasi-Newton method for the problem</p><pre><code class="language-none">min f(x) + h(x)</code></pre><p>where f: ℝⁿ → ℝ is C¹ and h: ℝⁿ → ℝ is lower semi-continuous, proper and prox-bounded.</p><p>About each iterate xₖ, a step sₖ is computed as an approximate solution of</p><pre><code class="language-none">min  φ(s; xₖ) + ½ σₖ ‖s‖² + ψ(s; xₖ)</code></pre><p>where φ(s; xₖ) = f(xₖ) + ∇f(xₖ)ᵀs + ½ sᵀBₖs  is a quadratic approximation of f about xₖ, ψ(s; xₖ) = h(xₖ + s) and σₖ &gt; 0 is the regularization parameter. The subproblem is solved inexactly by way of a first-order method such as the proximal-gradient method or the quadratic regularization method.</p><p><strong>Arguments</strong></p><ul><li><code>nlp::AbstractNLPModel</code>: a smooth optimization problem</li><li><code>h</code>: a regularizer such as those defined in ProximalOperators</li><li><code>options::ROSolverOptions</code>: a structure containing algorithmic parameters.</li></ul><p>The objective, gradient and Hessian of <code>nlp</code> will be accessed. The Hessian is accessed as an abstract operator and need not be the exact Hessian.</p><p><strong>Keyword arguments</strong></p><ul><li><code>x0::AbstractVector</code>: an initial guess (default: <code>nlp.meta.x0</code>)</li><li><code>subsolver_logger::AbstractLogger</code>: a logger to pass to the subproblem solver (default: the null logger)</li><li><code>subsolver</code>: the procedure used to compute a step (<code>R2DH</code>, <code>R2</code> or <code>PG</code>)</li><li><code>subsolver_options::ROSolverOptions</code>: default options to pass to the subsolver (default: all defaut options)</li><li><code>Mmonotone::Int</code>: number of previous values of the objective to consider for the non-monotone variant (default: 1).</li><li><code>selected::AbstractVector{&lt;:Integer}</code>: subset of variables to which <code>h</code> is applied (default <code>1:nlp.meta.nvar</code>).</li></ul><p><strong>Return values</strong></p><ul><li><code>xk</code>: the final iterate</li><li><code>Fobj_hist</code>: an array with the history of values of the smooth objective</li><li><code>Hobj_hist</code>: an array with the history of values of the nonsmooth objective</li><li><code>Complex_hist</code>: an array with the history of number of inner iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/R2N.jl#L3-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.RegularizedExecutionStats-Union{Tuple{RegularizedProblems.AbstractRegularizedNLPModel{T, V}}, Tuple{V}, Tuple{T}} where {T, V}" href="#RegularizedOptimization.RegularizedExecutionStats-Union{Tuple{RegularizedProblems.AbstractRegularizedNLPModel{T, V}}, Tuple{V}, Tuple{T}} where {T, V}"><code>RegularizedOptimization.RegularizedExecutionStats</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">GenericExecutionStats(reg_nlp :: AbstractRegularizedNLPModel{T, V})</code></pre><p>Construct a GenericExecutionStats object from an AbstractRegularizedNLPModel.  More specifically, construct a GenericExecutionStats on the NLPModel of reg<em>nlp and add three solver</em>specific entries namely :smooth<em>obj, :nonsmooth</em>obj and :xi. This is useful for reducing the number of allocations when calling solve!(..., reg<em>nlp, stats) and should be used by default. Warning: This should <em>not</em> be used when adding other solver</em>specific entries that do not have the current scalar type. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/utils.jl#L102-L109">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.TR-Union{Tuple{R}, Tuple{X}, Tuple{H}, Tuple{NLPModels.AbstractNLPModel, H, X, ROSolverOptions{R}}} where {H, X, R}" href="#RegularizedOptimization.TR-Union{Tuple{R}, Tuple{X}, Tuple{H}, Tuple{NLPModels.AbstractNLPModel, H, X, ROSolverOptions{R}}} where {H, X, R}"><code>RegularizedOptimization.TR</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">TR(nlp, h, χ, options; kwargs...)</code></pre><p>A trust-region method for the problem</p><pre><code class="language-none">min f(x) + h(x)</code></pre><p>where f: ℝⁿ → ℝ has a Lipschitz-continuous Jacobian, and h: ℝⁿ → ℝ is lower semi-continuous and proper.</p><p>About each iterate xₖ, a step sₖ is computed as an approximate solution of</p><pre><code class="language-none">min  φ(s; xₖ) + ψ(s; xₖ)  subject to  ‖s‖ ≤ Δₖ</code></pre><p>where φ(s ; xₖ) = f(xₖ) + ∇f(xₖ)ᵀs + ½ sᵀ Bₖ s  is a quadratic approximation of f about xₖ, ψ(s; xₖ) = h(xₖ + s), ‖⋅‖ is a user-defined norm and Δₖ &gt; 0 is the trust-region radius. The subproblem is solved inexactly by way of a first-order method such as the proximal-gradient method or the quadratic regularization method.</p><p><strong>Arguments</strong></p><ul><li><code>nlp::AbstractNLPModel</code>: a smooth optimization problem</li><li><code>h</code>: a regularizer such as those defined in ProximalOperators</li><li><code>χ</code>: a norm used to define the trust region in the form of a regularizer</li><li><code>options::ROSolverOptions</code>: a structure containing algorithmic parameters</li></ul><p>The objective, gradient and Hessian of <code>nlp</code> will be accessed. The Hessian is accessed as an abstract operator and need not be the exact Hessian.</p><p><strong>Keyword arguments</strong></p><ul><li><code>x0::AbstractVector</code>: an initial guess (default: <code>nlp.meta.x0</code>)</li><li><code>subsolver_logger::AbstractLogger</code>: a logger to pass to the subproblem solver (default: the null logger)</li><li><code>subsolver</code>: the procedure used to compute a step (<code>PG</code>, <code>R2</code> or <code>TRDH</code>)</li><li><code>subsolver_options::ROSolverOptions</code>: default options to pass to the subsolver (default: all defaut options)</li><li><code>selected::AbstractVector{&lt;:Integer}</code>: (default <code>1:f.meta.nvar</code>).</li></ul><p><strong>Return values</strong></p><ul><li><code>xk</code>: the final iterate</li><li><code>Fobj_hist</code>: an array with the history of values of the smooth objective</li><li><code>Hobj_hist</code>: an array with the history of values of the nonsmooth objective</li><li><code>Complex_hist</code>: an array with the history of number of inner iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/TR_alg.jl#L3-L46">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.TRDH-Union{Tuple{S}, Tuple{R}, Tuple{NLPModelsModifiers.AbstractDiagonalQNModel{R, S}, Any, Any, ROSolverOptions{R}}} where {R&lt;:Real, S}" href="#RegularizedOptimization.TRDH-Union{Tuple{S}, Tuple{R}, Tuple{NLPModelsModifiers.AbstractDiagonalQNModel{R, S}, Any, Any, ROSolverOptions{R}}} where {R&lt;:Real, S}"><code>RegularizedOptimization.TRDH</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">TRDH(nlp, h, χ, options; kwargs...)
TRDH(f, ∇f!, h, options, x0)</code></pre><p>A trust-region method with diagonal Hessian approximation for the problem</p><pre><code class="language-none">min f(x) + h(x)</code></pre><p>where f: ℝⁿ → ℝ has a Lipschitz-continuous Jacobian, and h: ℝⁿ → ℝ is lower semi-continuous and proper.</p><p>About each iterate xₖ, a step sₖ is computed as an approximate solution of</p><pre><code class="language-none">min  φ(s; xₖ) + ψ(s; xₖ)  subject to  ‖s‖ ≤ Δₖ</code></pre><p>where φ(s ; xₖ) = f(xₖ) + ∇f(xₖ)ᵀs + ½ sᵀ Dₖ s  is a quadratic approximation of f about xₖ, ψ(s; xₖ) = h(xₖ + s), ‖⋅‖ is a user-defined norm, Dₖ is a diagonal Hessian approximation and Δₖ &gt; 0 is the trust-region radius.</p><p><strong>Arguments</strong></p><ul><li><code>nlp::AbstractDiagonalQNModel</code>: a smooth optimization problem</li><li><code>h</code>: a regularizer such as those defined in ProximalOperators</li><li><code>χ</code>: a norm used to define the trust region in the form of a regularizer</li><li><code>options::ROSolverOptions</code>: a structure containing algorithmic parameters</li></ul><p>The objective and gradient of <code>nlp</code> will be accessed.</p><p>In the second form, instead of <code>nlp</code>, the user may pass in</p><ul><li><code>f</code> a function such that <code>f(x)</code> returns the value of f at x</li><li><code>∇f!</code> a function to evaluate the gradient in place, i.e., such that <code>∇f!(g, x)</code> store ∇f(x) in <code>g</code></li><li><code>x0::AbstractVector</code>: an initial guess.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>x0::AbstractVector</code>: an initial guess (default: <code>nlp.meta.x0</code>)</li><li><code>selected::AbstractVector{&lt;:Integer}</code>: (default <code>1:f.meta.nvar</code>)</li></ul><p><strong>Return values</strong></p><ul><li><code>xk</code>: the final iterate</li><li><code>Fobj_hist</code>: an array with the history of values of the smooth objective</li><li><code>Hobj_hist</code>: an array with the history of values of the nonsmooth objective</li><li><code>Complex_hist</code>: an array with the history of number of inner iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/TRDH_alg.jl#L3-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.project_y!-Tuple{Percival.AugLagModel}" href="#RegularizedOptimization.project_y!-Tuple{Percival.AugLagModel}"><code>RegularizedOptimization.project_y!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">project_y!(nlp)</code></pre><p>Given an <code>AugLagModel</code>, project <code>nlp.y</code> into [ymin, ymax] and updates <code>nlp.μc_y</code> accordingly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/AL_alg.jl#L376-L380">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.prox_split_1w-NTuple{4, Any}" href="#RegularizedOptimization.prox_split_1w-NTuple{4, Any}"><code>RegularizedOptimization.prox_split_1w</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Solves descent direction s for some objective function with the structure 	min<em>s q</em>k(s) + ψ(x+s) s.t. ||s||<em>q⩽ Δ 	for some Δ provided Arguments ––––– proxp : prox method for p-norm 	takes in z (vector), a (λ||⋅||</em>p), p is norm for ψ I think s0 : Vector{Float64,1} 	Initial guess for the descent direction projq : generic that projects onto ||⋅||<em>q⩽Δ norm ball options : mutable structure p</em>params</p><p><strong>Returns</strong></p><p>s   : Vector{Float64,1} 	Final value of Algorithm 6.1 descent direction w   : Vector{Float64,1} 	relaxation variable of Algorithm 6.1 descent direction</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/splitting.jl#L3-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RegularizedOptimization.prox_split_2w-NTuple{4, Any}" href="#RegularizedOptimization.prox_split_2w-NTuple{4, Any}"><code>RegularizedOptimization.prox_split_2w</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Solves descent direction s for some objective function with the structure 	min<em>s q</em>k(s) + ψ(x+s) s.t. ||s||<em>q⩽ Δ 	for some Δ provided Arguments ––––– proxp : prox method for p-norm 	takes in z (vector), a (λ||⋅||</em>p), p is norm for ψ I think s0 : Vector{Float64,1} 	Initial guess for the descent direction projq : generic that projects onto ||⋅||<em>q⩽Δ norm ball options : mutable structure p</em>params</p><p><strong>Returns</strong></p><p>s   : Vector{Float64,1} 	Final value of Algorithm 6.2 descent direction w   : Vector{Float64,1} 	relaxation variable of Algorithm 6.2 descent direction</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl/blob/4a32a63d897ff3b30835c97b0aa3d9784d8e303e/src/splitting.jl#L96-L116">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Tutorial</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 10 April 2025 19:12">Thursday 10 April 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
