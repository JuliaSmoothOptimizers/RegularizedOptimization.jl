
@Article{         andrei-2019,
  Author        = {Neculai Andrei},
  Title         = {A diagonal quasi-{N}ewton updating method for unconstrained optimization},
  Journal       = numalg,
  Year          = 2019,
  Volume        = 81,
  Pages         = {575-–590},
  doi           = {10.1007/s11075-018-0562-7},
  abstract      = {A diagonal quasi-Newton updating algorithm is presented. The elements of the diagonal matrix approximating the Hessian are determined by minimizing both the size of the change from the previous estimate and the trace of the update, subject to the weak secant equation. Under mild classical assumptions, the convergence of the algorithm is proved to be linear. The diagonal quasi-Newton update satisfies the bounded deterioration property. Numerical experiments with 80 unconstrained optimization test problems of different structures and complexities prove that the suggested algorithm is more efficient and more robust than the steepest descent, Cauchy with Oren and Luenberger scaling algorithm in its complementary form and classical Broyden-Fletcher-Goldfarb-Shanno algorithm.},
}

@Article{         aravkin-baraldi-orban-2022,
  Author        = {A. Y. Aravkin and R. Baraldi and D. Orban},
  Title         = {A Proximal Quasi-{N}ewton Trust-Region Method for Nonsmooth Regularized Optimization},
  Journal       = siopt,
  Year          = 2022,
  Volume        = 32,
  Number        = 2,
  Pages         = {900--929},
  doi           = {10.1137/21M1409536},
  abstract      = { We develop a trust-region method for minimizing the sum of a smooth term (f) and a nonsmooth term (h), both of which can be nonconvex. Each iteration of our method minimizes a possibly nonconvex model of (f + h) in a trust region. The model coincides with (f + h) in value and subdifferential at the center. We establish global convergence to a first-order stationary point when (f) satisfies a smoothness condition that holds, in particular, when it has a Lipschitz-continuous gradient, and (h) is proper and lower semicontinuous. The model of (h) is required to be proper, lower semi-continuous and prox-bounded. Under these weak assumptions, we establish a worst-case (O(1/\epsilon^2)) iteration complexity bound that matches the best known complexity bound of standard trust-region methods for smooth optimization. We detail a special instance, named TR-PG, in which we use a limited-memory quasi-Newton model of (f) and compute a step with the proximal gradient method,
                  resulting in a practical proximal quasi-Newton method. We establish similar convergence properties and complexity bound for a quadratic regularization variant, named R2, and provide an interpretation as a proximal gradient method with adaptive step size for nonconvex problems. R2 may also be used to compute steps inside the trust-region method, resulting in an implementation named TR-R2. We describe our Julia implementations and report numerical results on inverse problems from sparse optimization and signal processing. Both TR-PG and TR-R2 exhibit promising performance and compare favorably with two linesearch proximal quasi-Newton methods based on convex models. },
}

@Article{         aravkin-baraldi-orban-2024,
  Author        = {Aravkin, Aleksandr Y. and Baraldi, Robert and Orban, Dominique},
  Title         = {A {L}evenberg–{M}arquardt Method for Nonsmooth Regularized Least Squares},
  Journal       = sisc,
  Year          = 2024,
  Volume        = 46,
  Number        = 4,
  Pages         = {A2557--A2581},
  doi           = {10.1137/22M1538971},
  preprint      = {https://www.gerad.ca/en/papers/G-2022-58/view},
  grant         = nserc,
  abstract      = { Abstract. We develop a Levenberg–Marquardt method for minimizing the sum of a smooth nonlinear least-squares term \(f(x) = \frac{1}{2} \|F(x)\|\_2^2\) and a nonsmooth term \(h\). Both \(f\) and \(h\) may be nonconvex. Steps are computed by minimizing the sum of a regularized linear least-squares model and a model of \(h\) using a first-order method such as the proximal gradient method. We establish global convergence to a first-order stationary point under the assu mptions that \(F\) and its Jacobian are Lipschitz continuous and \(h\) is proper and lower semicontinuous. In the worst case, our method performs \(O(\epsilon^{-2})\) iterations to bring a measure of stationarity below \(\epsilon \in (0, 1)\) . We also derive a trust-region variant that enjoys similar asymptotic worst-case iteration complexity as a special case of the trust-region algorithm of Aravkin, Baraldi, and Orban [SIAM J. Optim., 32 (2022), pp. 900–929]. We report numerica l results on three
                  examples: a group-lasso basis-pursuit denoise example, a nonlinear support vector machine, and parameter estimation in a neuroscience application. To implement those examples, we describe in detail how to evaluate proximal operators for separable \(h\) and for the group lasso with trust-region constraint. In all cases, the Levenberg–Marquardt methods perform fewer outer iterations than either a proximal gradient method with adaptive step length or a quasi-Newto n trust-region method, neither of which exploit the least-squares structure of the problem. Our results also highlight the need for more sophisticated subproblem solvers than simple first-order methods. },
}

@Software{        baraldi-leconte-orban-regularized-optimization-2024,
  Author        = {R. Baraldi and G. Leconte and D. Orban},
  Title         = {{RegularizedOptimization.jl}: Algorithms for Regularized Optimization},
  Year          = 2024,
  license       = {MPL-2.0},
  url           = {https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl},
  doi           = {10.5281/zenodo.6940313},
}

@Software{        leconte_linearoperators_jl_linear_operators_2023,
  Author        = {Leconte, Geoffroy and Orban, Dominique and Soares Siqueira, Abel and contributors},
  license       = {MPL-2.0},
  Title         = {{LinearOperators.jl: Linear Operators for Julia}},
  url           = {https://github.com/JuliaSmoothOptimizers/LinearOperators.jl},
  version       = {2.6.0},
  Year          = 2023,
}

@Article{         birgin-martinez-raydan-2014,
  Author        = {Birgin, Ernesto G. and Martínez, Jose Mario and Raydan, Marcos},
  Title         = {Spectral Projected Gradient Methods: Review and Perspectives},
  Journal       = jssoft,
  Year          = 2014,
  Volume        = 60,
  Number        = 3,
  Pages         = {1--21},
  doi           = {10.18637/jss.v060.i03},
  abstract      = {Over the last two decades, it has been observed that using the gradient vector as a search direction in large-scale optimization may lead to efficient algorithms. The effectiveness relies on choosing the step lengths according to novel ideas that are related to the spectrum of the underlying local Hessian rather than related to the standard decrease in the objective function. A review of these so-called spectral projected gradient methods for convex constrained optimization is presented. To illustrate the performance of these low-cost schemes, an optimization problem on the set of positive definite matrices is described.},
}

@Article{         bolte-sabach-teboulle-2014,
  Author        = {Bolte, J. and Sabach, S. and Teboulle, M.},
  Title         = {Proximal alternating linearized minimization for nonconvex and nonsmooth problems},
  Journal       = mp,
  Year          = 2014,
  Number        = 146,
  Pages         = {459–-494},
  doi           = {10.1007/s10107-013-0701-9},
}

@Article{         dennis-wolkowicz-1993,
  Author        = {Dennis, Jr., J. E. and Wolkowicz, H.},
  Title         = {Sizing and Least-Change Secant Methods},
  Journal       = sinum,
  Year          = 1993,
  Volume        = 30,
  Number        = 5,
  Pages         = {1291--1314},
  doi           = {10.1137/0730067},
  abstract      = { Oren and Luenberger introduced in 1974 a strategy for replacing Hessian approximations by their scalar multiples and then performing quasi-Newton updates, generally least-change secant updates such as the BFGS or DFP updates [Oren and Luenberger, Management Sci., 20 (1974), pp. 845–862]. In this paper, the function \[\omega (A) = \left( {\frac{{{{{\operatorname{trace}}(A)} / n}}}{{{\operatorname{det}}(A)^{{1 / n}} }}} \right)\] is shown to be a measure of change with a direct connection to the Oren–Luenberger strategy. This measure is interesting because it is related to the \$\ell\_2\$ condition number, but it takes all the eigenvalues of A into account rather than just the extremes. If the class of possible updates is restricted to the Broyden class, i.e., scalar premultiples are not allowed, then the optimal update depends on the dimension of the problem. It may, or may not, be in the convex class, but it becomes the BFGS update as the dimension increases.
                  This seems to be yet another explanation for why the optimally conditioned updates are not significantly better than the BFGS update. The theory results in several new interesting updates including a self-scaling, hereditarily positive definite, update in the Broyden class which is not necessarily in the convex class. This update, in conjunction with the Oren–Luenberger scaling strategy at the first iteration only, was consistently the best in numerical tests. },
}

@Article{         gilbert-lemarechal-1989,
  Author        = {Gilbert, J.-C. and Lemaréchal, C.},
  Title         = {Some numerical experiments with variable-storage quasi-{N}ewton algorithms},
  Journal       = mp,
  Year          = 1989,
  Volume        = 45,
  Pages         = {407--435},
  doi           = {10.1007/BF01589113},
}

@TechReport{      aravkin-baraldi-leconte-orban-2021,
  Author        = {Aravkin, Aleksandr and Baraldi, Robert and Leconte, Geoffroy and Orban, Dominique},
  Title         = {Corrigendum: A proximal quasi-{N}ewton trust-region method for nonsmooth regularized optimization},
  Institution   = gerad,
  Year          = 2024,
  Type          = {Cahier},
  Number        = {G-2021-12-SM},
  Address       = gerad-address,
  Pages         = {1--3},
  doi           = {10.13140/RG.2.2.36250.45768},
}

@Article{         bot-csetnek-laszlo-2016,
  Author        = {Boţ, R. I. and Csetnek, E. R. and László, S.C.},
  Title         = {An inertial forward–backward algorithm for the minimization of the sum of two nonconvex functions},
  Journal       = euro,
  Year          = 2016,
  Number        = 4,
  Pages         = {3--25},
  doi           = {10.1007/s13675-015-0045-8},
}

@Article{         cartis-gould-toint-2011,
  Author        = {Cartis, Coralia and Gould, Nicholas I. M. and Toint, {\relax Ph}. L.},
  Title         = {On the Evaluation Complexity of Composite Function Minimization with Applications to Nonconvex Nonlinear Programming},
  Journal       = siopt,
  Year          = 2011,
  Volume        = 21,
  Number        = 4,
  Pages         = {1721--1739},
  doi           = {10.1137/11082381X},
}

@Article{         fukushima-mine-1981,
  Author        = {Masao Fukushima and Hisashi Mine},
  Title         = {A generalized proximal point algorithm for certain non-convex minimization problems},
  Journal       = ijss,
  Year          = 1981,
  Volume        = 12,
  Number        = 8,
  Pages         = {989--1000},
  Publisher     = {Taylor & Francis},
  doi           = {10.1080/00207728108963798},
}

@Article{         lee-sun-saunders-2014,
  Author        = {Lee, Jason D. and Sun, Yuekai and Saunders, Michael A.},
  Title         = {Proximal {N}ewton-Type Methods for Minimizing Composite Functions},
  Journal       = siopt,
  Year          = 2014,
  Volume        = 24,
  Number        = 3,
  Pages         = {1420--1443},
  doi           = {10.1137/130921428},
}

@TechReport{      leconte-orban-2023,
  Author        = {G. Leconte and D. Orban},
  Title         = {The Indefinite Proximal Gradient Method},
  Institution   = gerad,
  Year          = 2023,
  Type          = {Cahier},
  Number        = {G-2023-37},
  Address       = gerad-address,
  doi           = {10.13140/RG.2.2.11836.41606},
}

@TechReport{      leconte-orban-2024,
  Author        = {Leconte, Geoffroy and Orban, Dominique},
  Title         = {An interior-point trust-region method for nonsmooth regularized bound-constrained optimization},
  Institution   = gerad,
  Year          = 2024,
  Type          = {Cahier},
  Number        = {G-2024-17},
  Address       = gerad-address,
  doi           = {10.13140/RG.2.2.18132.99201},
}

@InProceedings{   li-lin-2015,
  Author        = {Li, Huan and Lin, Zhouchen},
  Title         = {Accelerated Proximal Gradient Methods for Nonconvex Programming},
  Booktitle     = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1},
  Year          = 2015,
  Series        = {NIPS'15},
  Pages         = {379--387},
  Address       = {Cambridge, MA, USA},
  Publisher     = {MIT Press},
  abstract      = {Nonconvex and nonsmooth problems have recently received considerable attention in signal/image processing, statistics and machine learning. However, solving the nonconvex and nonsmooth optimization problems remains a big challenge. Accelerated proximal gradient (APG) is an excellent method for convex programming. However, it is still unknown whether the usual APG can ensure the convergence to a critical point in nonconvex programming. In this paper, we extend APG for general nonconvex and nonsmooth programs by introducing a monitor that satisfies the sufficient descent property. Accordingly, we propose a monotone APG and a nonmonotone APG. The latter waives the requirement on monotonic reduction of the objective function and needs less computation in each iteration. To the best of our knowledge, we are the first to provide APG-type algorithms for general nonconvex and nonsmooth problems ensuring that every accumulation point is a critical point, and the convergence
                  rates remain O(1/k2) when the problems are convex, in which k is the number of iterations. Numerical results testify to the advantage of our algorithms in speed.},
  numpages      = 9,
  location      = {Montreal, Canada},
  url           = {http://irc.cs.sdu.edu.cn/973project/result/download/2015/28.AcceleratedProximal.pdf},
}

@Article{         lions-mercier-1979,
  Author        = {P.-L. Lions and B. Mercier},
  Title         = {Splitting algorithms for the sum of two nonlinear operators},
  Journal       = sinum,
  Year          = 1979,
  Volume        = 16,
  Number        = 6,
  Pages         = {964--979},
  doi           = {10.1137/0716071},
}

@Article{         kanzow-lechner-2021,
  Author        = {Kanzow, C and Lechner, T},
  Title         = {Globalized inexact proximal {N}ewton-type methods for nonconvex composite functions},
  Journal       = coap,
  Year          = 2021,
  Volume        = 78,
  Number        = 2,
  Pages         = {377--410},
  doi           = {10.1007/s10589-020-00243-6},
  abstract      = {Optimization problems with composite functions consist of an objective function which is the sum of a smooth and a (convex) nonsmooth term. This particular structure is exploited by the class of proximal gradient methods and some of their generalizations like proximal Newton and quasi-Newton methods. The current literature on these classes of methods almost exclusively considers the case where also the smooth term is convex. Here we present a globalized proximal Newton-type method which allows the smooth term to be nonconvex. The method is shown to have nice global and local convergence properties, and some numerical results indicate that this method is very promising also from a practical point of view.},
}

@Article{         zhu-nazareth-wolkowicz-1999,
  Author        = {Zhu, M and Nazareth, J L and Wolkowicz, H},
  Title         = {The Quasi-{C}auchy Relation and Diagonal Updating},
  Journal       = siopt,
  Year          = 1999,
  Volume        = 9,
  Number        = 4,
  Pages         = {1192--1204},
  doi           = {10.1137/S1052623498331793},
  abstract      = { The quasi-Cauchy (QC) relation is the weak quasi-Newton relation of Dennis and Wolkowicz [SIAM J. Numer. Anal., 30 (1993), pp. 1291--1314] with the added restriction that full matrices are replaced by diagonal matrices. This relation is justified and explored and, in particular, two basic variational techniques for updating diagonal matrices that satisfy it are formulated.For purposes of illustration, a numerical experiment is described where a diagonal updated matrix with hereditary positive definiteness is used to precondition Cauchy's steepest-descent direction. The resulting QC algorithm is shown to be significantly accelerated.In the concluding section, the following topics are briefly discussed: additional variational principles, use of diagonal updates within other optimization algorithms together with some further numerical experience (summarized in an appendix), and an interesting connection between QC-diagonal updating and trust-region techniques. },
}

@Book{            conn-gould-toint-2000,
  Author        = {A. R. Conn and N. I. M. Gould and {\relax Ph}. L. Toint},
  Title         = {Trust-region methods},
  Publisher     = siam,
  Year          = 2000,
  Series        = {MOS-SIAM Series on Optimization},
  Address       = siam-address,
  Number        = 1,
  doi           = {10.1137/1.9780898719857},
}

@Book{            rockafellar-wets-1998,
  Author        = {{R. Tyrrell} Rockafellar and Roger J.-B. Wets},
  Title         = {Variational Analysis},
  Publisher     = {Springer Verlag},
  Year          = 1998,
  Address       = {Heidelberg, Berlin, New York},
  doi           = {10.1007/978-3-642-02431-3},
}

@TechReport{      leconte-orban-2023-2,
  Author        = {Leconte, Geoffroy and Orban, Dominique},
  Title         = {Complexity of trust-region methods with unbounded {H}essian approximations for smooth and nonsmooth optimization},
  Institution   = gerad,
  Year          = 2023,
  Type          = {Cahier},
  Number        = {G-2023-65},
  Address       = gerad-address,
  url           = {https://www.gerad.ca/fr/papers/G-2023-65},
}

@Article{         kanzow-mehlitz-2022,
  Author        = {Kanzow, Christian and Mehlitz, Patrick},
  Title         = {Convergence properties of monotone and nonmonotone proximal gradient methods revisited},
  Journal       = jota,
  Year          = 2022,
  Volume        = 195,
  Number        = 2,
  Pages         = {624--646},
  doi           = {10.1007/s10957-022-02101-3},
  Publisher     = {Springer},
}

@Article{         chouzenoux-pesquet-repetti-2014,
  Author        = {Chouzenoux, Emilie and Pesquet, Jean-Christophe and Repetti, Audrey},
  Title         = {Variable metric forward--backward algorithm for minimizing the sum of a differentiable function and a convex function},
  Journal       = jota,
  Year          = 2014,
  Volume        = 162,
  Number        = 1,
  Pages         = {107--132},
  Publisher     = {Springer},
  doi           = {10.1007/s10957-013-0465-7},
}

@TechReport{      diouane-habiboullah-orban-2024,
  Author        = {Youssef Diouane and Mohamed Laghdaf Habiboullah and Dominique Orban},
  Title         = {Complexity of trust-region methods in the presence of unbounded {H}essian approximations},
  Institution   = {GERAD},
  Year          = 2024,
  Type          = {Cahier},
  Number        = {G-2024-43},
  Address       = {Montr\'eal, Canada},
  doi           = {10.48550/arXiv.2408.06243},
  url           = {https://www.gerad.ca/fr/papers/G-2024-43},
}

@Article{         powell-2010,
  Author        = {Powell, M. J. D.},
  Title         = {On the convergence of a wide range of trust region methods for unconstrained optimization},
  Journal       = imajna,
  Year          = 2010,
  Volume        = 30,
  Number        = 1,
  Pages         = {289--301},
  doi           = {10.1093/imanum/drp021},
}

@Article{         nazareth-1995,
  Author        = {J. L. Nazareth},
  Title         = {If quasi-{N}ewton then why not quasi-{C}auchy?},
  Journal       = {SIAG/OPT Views-and-News},
  Year          = 1995,
  Volume        = 6,
  Pages         = {11--14},
}

@InProceedings{   stella-themelis-sopasakis-patrinos-2017,
  Author        = {L. {Stella} and A. {Themelis} and P. {Sopasakis} and P. {Patrinos}},
  Title         = {A simple and efficient algorithm for nonlinear model predictive control},
  Booktitle     = {2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  Year          = 2017,
  Pages         = {1939--1944},
  doi           = {10.1109/CDC.2017.8263933},
}

@Article{         themelis-stella-patrinos-2017,
  Author        = {Themelis, Andreas and Stella, Lorenzo and Patrinos, Panagiotis},
  Title         = {Forward-Backward Envelope for the Sum of Two Nonconvex Functions: Further Properties and Nonmonotone line seach Algorithms},
  Journal       = siopt,
  Year          = 2018,
  Volume        = 28,
  Number        = 3,
  Pages         = {2274--2303},
  doi           = {10.1137/16M1080240},
}

@Article{         yu-zhang-2022,
  Author        = {Yu, Quan and Zhang, Xinzhen},
  Title         = {A smoothing proximal gradient algorithm for matrix rank minimization problem},
  Journal       = coap,
  Year          = 2022,
  Pages         = {1--20},
  doi           = {10.1007/s10589-021-00337-9},
  Publisher     = {Springer},
}

@Article{         chouzenoux-martin-pesquet-2023,
  Author        = {Chouzenoux, Emilie and Martin, S{\'e}gol{\`e}ne and Pesquet, Jean-Christophe},
  Title         = {A local {MM} subspace method for solving constrained variational problems in image recovery},
  Journal       = jmiv,
  Year          = 2023,
  Volume        = 65,
  Number        = 2,
  Pages         = {253--276},
  doi           = {10.1007/s10851-022-01112-z},
  Publisher     = {Springer},
}

@Article{         stella-themelis-patrinos-2017,
  Author        = {Stella, Lorenzo and Themelis, Andreas and Patrinos, Panagiotis},
  Title         = {Forward--backward quasi-{N}ewton methods for nonsmooth optimization problems},
  Journal       = coap,
  Year          = 2017,
  Volume        = 67,
  Number        = 3,
  Pages         = {443--487},
  doi           = {10.1007/s10589-017-9912-y},
  Publisher     = {Springer},
}

@TechReport{      diouane-gollier-orban-2024,
  Author        = {Youssef Diouane and Maxence Gollier and Dominique Orban},
  Title         = {A nonsmooth exact penalty method for equality-constrained optimization: complexity and implementation},
  Institution   = {GERAD},
  Year          = 2024,
  Type          = {Cahier},
  Number        = {G-2024-65},
  Address       = {Montr\'eal, Canada},
  doi           = {10.13140/RG.2.2.16095.47527},
}

@InProceedings{   becker-fadili-2012,
  Author        = {Becker, Stephen and Fadili, Jalal},
  Title         = {A quasi-{N}ewton proximal splitting method},
  Editor        = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
  Booktitle     = {Advances in Neural Information Processing Systems},
  Year          = 2012,
  Volume        = 25,
  Publisher     = {Curran Associates, Inc.},
  url           = {https://proceedings.neurips.cc/paper_files/paper/2012/file/e034fb6b66aacc1d48f445ddfb08da98-Paper.pdf},
}

@Article{         liu-pan-wu-yang-2024,
  Author        = {Liu, Ruyu and Pan, Shaohua and Wu, Yuqia and Yang, Xiaoqi},
  Title         = {An inexact regularized proximal {N}ewton method for nonconvex and nonsmooth optimization},
  Journal       = coap,
  Year          = 2024,
  Volume        = 88,
  Number        = 2,
  Pages         = {603--641},
  Publisher     = springer,
  doi           = {10.1007/s10589-024-00560-0},
}

@Article{         de-marchi-2023,
  Author        = {De Marchi, Alberto},
  Title         = {Proximal gradient methods beyond monotony},
  Journal       = {J Nonsmooth Anal Optim},
  Year          = 2023,
  Volume        = 4,
  Number        = {Original research articles},
  Publisher     = {Episciences.org},
  doi           = {10.46298/jnsao-2023-10290},
}

@Article{         kanzow-lechner-2024,
  Author        = {Kanzow, Christian and Lechner, Theresa},
  Title         = {Efficient Regularized Proximal Quasi-{N}ewton Methods for Large-Scale Nonconvex Composite Optimization Problems},
  Journal       = {PAC J OPTIM},
  Year          = 2024,
  Volume        = 20,
  Number        = 3,
  Pages         = {537--568},
  doi           = {10.61208/pjo-2023-036},
}

@Article{         becker-fadili-ochs-2019,
  Author        = {Becker, Stephen and Fadili, Jalal and Ochs, Peter},
  Title         = {On Quasi-{N}ewton Forward-Backward Splitting: Proximal Calculus and Convergence},
  Journal       = siopt,
  Year          = 2019,
  Volume        = 29,
  Number        = 4,
  Pages         = {2445--2481},
  doi           = {10.1137/18M1167152},
}

@Article{         jia-kanzow-mehlitz-2023,
  Author        = {Jia, Xiaoxi and Kanzow, Christian and Mehlitz, Patrick},
  Title         = {Convergence Analysis of the Proximal Gradient Method in the Presence of the {K}urdyka–{\L{}}ojasiewicz Property Without Global {L}ipschitz Assumptions},
  Journal       = siopt,
  Year          = 2023,
  Volume        = 33,
  Number        = 4,
  Pages         = {3038--3056},
  doi           = {10.1137/23M1548293},
}
